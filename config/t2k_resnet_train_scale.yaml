data:
  split_path: '/scratch/fcormier/t2k/ml/output_skdetsim/jan23_electrons_forRegression_5M_1/train_val_test_gt200Hits_FCTEST_nFolds20_fold0.npz' 
  dataset:
    h5file: '$SLURM_TMPDIR/digi_combine.hy'
    _target_: watchmal.dataset.cnn.cnn_dataset.CNNDatasetScale
    pmt_positions_file: /data/thoriba/t2k/imagefile/skdetsim_imagefile.npy
    use_positions: False
    geometry_file: /home/fcormier/t2k/ml/training/t2k_ml_training/data/geofile_skdetsim.npz
    channel_scaler:
      fitted_scaler: null # set None to fit a new scaler, if provided, only this and transform_per_batch will be used.
      scaler_type: ['robust']  # must be a list; even if you have only one thing. 
      sample_size: 10000  # sample size to fit the scaler
      dataset_index_file: '/data/thoriba/t2k/indices/apr3_eMuPiPlus_1500MeV_small_1/train_val_test_gt200Hits_FCTEST_nFolds10_fold0.npz'
      transform_per_batch: False    # must be False now.
      scaler_output_path: '/data/thoriba/t2k/indices/testingCNN/' # where to save the file
model:
  _target_: watchmal.model.resnet.resnet18
  num_input_channels: 2
  num_output_channels: 3
  stride: 1
  kernelSize: 1
  dropout_p: 0.
  conv_pad_mode: 'zeros'
engine:
  _target_: watchmal.engine.regression.RegressionEngine
  truth_key: 'positions'
tasks:
  train:
    epochs: 30
    val_interval: 50
    num_val_batches: 5
    checkpointing: false
    loss:
      _target_: torch.nn.HuberLoss
      delta: 0.1
    data_loaders:
      train:
        split_key: train_idxs
        batch_size: 35
        num_workers: 2
        sampler:
          _target_: torch.utils.data.sampler.SubsetRandomSampler
      validation:
        split_key: val_idxs
        batch_size: 150
        num_workers: 2
        sampler:
          _target_: torch.utils.data.sampler.SubsetRandomSampler
    optimizers:
      _target_: torch.optim.Adam
      lr: 0.01
      weight_decay: 0
    scheduler:
      _target_: torch.optim.lr_scheduler.ExponentialLR
      gamma: 0.8
  evaluate:
    data_loaders:
      test:
        split_key: test_idxs
        batch_size: 1000
        num_workers: 2
        sampler:
          _target_: torch.utils.data.sampler.SubsetRandomSampler
gpu_list: 
- 6
seed: null
dump_path: ./outputs/
