{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "based-brush",
   "metadata": {},
   "source": [
    "\n",
    "<h1>Dataset Index Generation</h1>\n",
    "This is used to generate the indices for the training, validation, and test sets for four classes with pions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "central-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from progressbar import *\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib\n",
    "#from watchmal.testing.repeating_classifier_training_utils import *\n",
    "from functools import reduce\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adult-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_path = \"/fast_scratch/WatChMaL/data/IWCD_mPMT_Short_emgp0_E0to1000MeV_digihits.h5\"\n",
    "\n",
    "f = h5py.File(original_data_path, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "republican-jamaica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['angles', 'energies', 'event_hits_index', 'event_ids', 'hit_charge', 'hit_pmt', 'hit_time', 'labels', 'positions', 'root_files', 'veto', 'veto2']>\n",
      "<HDF5 dataset \"angles\": shape (23481549, 2), type \"<f4\">\n",
      "<HDF5 dataset \"energies\": shape (23481549, 1), type \"<f4\">\n",
      "<HDF5 dataset \"event_hits_index\": shape (23481549,), type \"<i8\">\n",
      "<HDF5 dataset \"event_ids\": shape (23481549,), type \"<i4\">\n",
      "<HDF5 dataset \"hit_charge\": shape (31533173829,), type \"<f4\">\n",
      "<HDF5 dataset \"hit_pmt\": shape (31533173829,), type \"<i4\">\n",
      "<HDF5 dataset \"hit_time\": shape (31533173829,), type \"<f4\">\n",
      "<HDF5 dataset \"labels\": shape (23481549,), type \"<i4\">\n",
      "<HDF5 dataset \"positions\": shape (23481549, 1, 3), type \"<f4\">\n",
      "<HDF5 dataset \"root_files\": shape (23481549,), type \"|O\">\n",
      "<HDF5 dataset \"veto\": shape (23481549,), type \"|b1\">\n",
      "<HDF5 dataset \"veto2\": shape (23481549,), type \"|b1\">\n"
     ]
    }
   ],
   "source": [
    "print(f.keys())\n",
    "\n",
    "for key in f.keys():\n",
    "    print(f[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "streaming-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_hit_pmt = f[\"hit_pmt\"]\n",
    "hdf5_hit_time = f[\"hit_time\"]\n",
    "hdf5_hit_charge = f[\"hit_charge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "colored-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_pmt = np.memmap(original_data_path, mode=\"r\", shape=hdf5_hit_pmt.shape,\n",
    "                                    offset=hdf5_hit_pmt.id.get_offset(), dtype=hdf5_hit_pmt.dtype)\n",
    "\n",
    "hit_time = np.memmap(original_data_path, mode=\"r\", shape=hdf5_hit_time.shape,\n",
    "                                    offset=hdf5_hit_time.id.get_offset(), dtype=hdf5_hit_time.dtype)\n",
    "\n",
    "hit_charge = np.memmap(original_data_path, mode=\"r\", shape=hdf5_hit_charge.shape,\n",
    "                                    offset=hdf5_hit_charge.id.get_offset(), dtype=hdf5_hit_charge.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assigned-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles     = np.array(f['angles'])\n",
    "energies   = np.array(f['energies'])\n",
    "positions  = np.array(f['positions'])\n",
    "labels     = np.array(f['labels'])\n",
    "root_files = np.array(f['root_files'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "executed-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict set\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Set up indices\n",
    "indices = np.array(range(len(labels)))\n",
    "\n",
    "# Set up dict of file indices\n",
    "file_dict = dict.fromkeys(root_files)\n",
    "print(\"Dict set\")\n",
    "\n",
    "for file in file_dict.keys():\n",
    "    file_dict[file] = []\n",
    "\n",
    "for idx, root_file in enumerate(root_files):\n",
    "    file_dict[root_file].append(idx)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "powered-boutique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "1000\n",
      "3000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Get files associated with each particle type\n",
    "\n",
    "gamma_indices = indices[np.where(labels == 0)]\n",
    "gamma_root_file_set = list(dict.fromkeys(root_files[gamma_indices]))\n",
    "\n",
    "e_indices     = indices[np.where(labels == 1)]\n",
    "e_root_file_set = list(dict.fromkeys(root_files[e_indices]))\n",
    "\n",
    "mu_indices    = indices[np.where(labels == 2)]\n",
    "mu_root_file_set = list(dict.fromkeys(root_files[mu_indices]))\n",
    "\n",
    "pion_indices    = indices[np.where(labels == 3)]\n",
    "pion_root_file_set = list(dict.fromkeys(root_files[pion_indices]))\n",
    "\n",
    "print(len(e_root_file_set))\n",
    "print(len(mu_root_file_set))\n",
    "print(len(gamma_root_file_set))\n",
    "print(len(pion_root_file_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "after-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_for_files(file_names):\n",
    "    all_indices = []\n",
    "    for file_name in file_names:\n",
    "        all_indices.extend(file_dict[file_name])\n",
    "    return np.array(all_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "desperate-jimmy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5900828 5900829 5900830 ... 7064964 7064965 7064966]\n"
     ]
    }
   ],
   "source": [
    "mu_test_files, mu_val_files, mu_train_files = mu_root_file_set[0:400], mu_root_file_set[400:500], mu_root_file_set[500:]\n",
    "\n",
    "mu_test_set, mu_val_set, mu_train_set = get_indices_for_files(mu_test_files), get_indices_for_files(mu_val_files), get_indices_for_files(mu_train_files)\n",
    "\n",
    "print(mu_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "statutory-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2944634 2944635 2944636 ... 5900825 5900826 5900827]\n"
     ]
    }
   ],
   "source": [
    "gamma_test_files, gamma_val_files, gamma_train_files = gamma_root_file_set[0:1000], gamma_root_file_set[1000:2000], gamma_root_file_set[2000:3000]\n",
    "\n",
    "gamma_test_set, gamma_val_set, gamma_train_set = get_indices_for_files(gamma_test_files), get_indices_for_files(gamma_val_files), get_indices_for_files(gamma_train_files)\n",
    "\n",
    "print(gamma_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amateur-charter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0       1       2 ... 2944631 2944632 2944633]\n"
     ]
    }
   ],
   "source": [
    "e_test_files, e_val_files, e_train_files = e_root_file_set[0:1000], e_root_file_set[1000:2000], e_root_file_set[2000:3000]\n",
    "\n",
    "e_test_set, e_val_set, e_train_set = get_indices_for_files(e_test_files), get_indices_for_files(e_val_files), get_indices_for_files(e_train_files)\n",
    "\n",
    "print(e_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "humanitarian-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20613195 20613196 20613197 ... 21760459 21760460 21760461]\n"
     ]
    }
   ],
   "source": [
    "pion_test_files, pion_val_files, pion_train_files = pion_root_file_set[0:400], pion_root_file_set[400:500], pion_root_file_set[500:1000]\n",
    "\n",
    "pion_test_set, pion_val_set, pion_train_set = get_indices_for_files(pion_test_files), get_indices_for_files(pion_val_files), get_indices_for_files(pion_train_files)\n",
    "\n",
    "print(pion_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "swiss-murray",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n",
      "{0}\n",
      "{2}\n",
      "{3}\n"
     ]
    }
   ],
   "source": [
    "# Verify that indices match\n",
    "all_e_indices = np.concatenate((e_test_set, e_val_set, e_train_set))\n",
    "print(set(labels[all_e_indices]))\n",
    "\n",
    "all_gamma_indices = np.concatenate((gamma_test_set, gamma_val_set, gamma_train_set))\n",
    "print(set(labels[all_gamma_indices]))\n",
    "\n",
    "all_mu_indices = np.concatenate((mu_test_set, mu_val_set, mu_train_set))\n",
    "print(set(labels[all_mu_indices]))\n",
    "\n",
    "all_pion_indices = np.concatenate((pion_test_set, pion_val_set, pion_train_set))\n",
    "print(set(labels[all_pion_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "concerned-plant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23481549\n",
      "17702123\n",
      "17702123\n"
     ]
    }
   ],
   "source": [
    "# Verify that all events are uniquely accounted for\n",
    "all_collected_indices = np.concatenate((e_test_set, e_val_set, e_train_set, gamma_test_set, gamma_val_set, gamma_train_set))\n",
    "\n",
    "print(len(labels))\n",
    "print(len(all_collected_indices))\n",
    "print(len(set(all_collected_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "academic-french",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17702123"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels) - (len(labels[all_mu_indices]) + len(labels[all_pion_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-costa",
   "metadata": {},
   "source": [
    "Hence, all_collected_indices contains only the indices for electrons and gammas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-arabic",
   "metadata": {},
   "source": [
    "Below, we concatenate only the electron and gamma data and leave out the muons and pions. So, this indices file has prepared data containing only electron and gamma events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adaptive-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = np.concatenate((e_train_set, gamma_train_set))\n",
    "val_idxs   = np.concatenate((e_val_set, gamma_val_set))\n",
    "test_idxs  = np.concatenate((e_test_set, gamma_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "finite-caribbean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17702123"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idxs) + len(val_idxs) + len(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "crucial-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez('/home/zpatel/IWCD_mPMT_Short_2_class_e_gamma_veto_idxs.npz', train_idxs=train_idxs, val_idxs=val_idxs, test_idxs=test_idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-depression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-prairie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
